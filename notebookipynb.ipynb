{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cowan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cosine(vec1, vec2):  # Scale vectors to both have unit length\n",
    "  unit_vec1 = vec1/np.linalg.norm(vec1)\n",
    "  unit_vec2 = vec2/np.linalg.norm(vec2)\n",
    "  # The dot product of unit vectors gives the cosine of their angle\n",
    "  return np.dot(unit_vec1,unit_vec2)\n",
    "\n",
    "\n",
    "def find_avg_vector(txt, embedding):\n",
    "  words = word_tokenize(txt)\n",
    "  vec_sum = None\n",
    "  count = 0\n",
    "  for word in words:\n",
    "    if word in embedding:\n",
    "      count += 1\n",
    "      if vec_sum is not None:\n",
    "        vec_sum += embedding[word]\n",
    "      else:\n",
    "        # The embeddings are read-only unless you copy them\n",
    "        vec_sum = embedding[word].copy()\n",
    "  if vec_sum is None:\n",
    "    return pd.Series(np.zeros((300,)))  # Treat no word found in embedding as zero vector\n",
    "  return pd.Series(vec_sum/count)\n",
    "\n",
    "def more_like_snippet_A(snippet, snippetA, snippetB, embedding):\n",
    "  snip_vec = find_avg_vector(snippet, embedding)\n",
    "  snip_A = find_avg_vector(snippetA, embedding)\n",
    "  snip_B = find_avg_vector(snippetB, embedding)\n",
    "  return find_cosine(snip_vec, snip_A) > find_cosine(snip_vec, snip_B)\n",
    "\n",
    "  tester = data.sample(100)\n",
    "  tester_array = tester[['comments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6207211\n",
      "great prof, very interesting, cute, just love the accent\n",
      "James  Daybell\n",
      "\n",
      "0.65127707\n",
      "Wonderful...really captivating and interesting, and hot!\n",
      "Vignault  Luc\n",
      "\n",
      "0.59274226\n",
      "So cute and oh so young.\n",
      "David  McNevin\n",
      "\n",
      "0.52990603\n",
      "not always clear, but alwasy entertaining and very sweet\n",
      "Michael  Scanlin\n",
      "\n",
      "0.5241624\n",
      "I can\\'t believe he does not have a hot pepper cuz this instructor is hot stuff. He can teach too. Fun class and funny guy.\n",
      "Brian  Storey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tester = data.sample(1000)\n",
    "#tester_array = tester[['comments']]\n",
    "#print(tester_array)\n",
    "maxx = 0\n",
    "for index, row in tester.iterrows():\n",
    "    #print(row['comments'])\n",
    "    #print(find_cosine(find_avg_vector(row['comments'], wv), find_avg_vector(\"This professor is attractive\",wv)))\n",
    "    if find_cosine(find_avg_vector(row['comments'], wv), find_avg_vector(\"cute attractive hot\",wv)) > 0.52:\n",
    "        maxx = find_cosine(find_avg_vector(row['comments'], wv), find_avg_vector(\"cute attractive hot\",wv))\n",
    "        print(maxx)\n",
    "        print(row['comments'])\n",
    "        print(row['professor_name'])\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   professor_name                                 school_name  \\\n",
      "0  Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "1  Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "2  Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "3  Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "4  Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "\n",
      "        department_name                    local_name state_name  \\\n",
      "0  Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "1  Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "2  Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "3  Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "4  Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "\n",
      "   year_since_first_review  star_rating take_again  diff_index  \\\n",
      "0                     11.0          4.7        NaN         2.0   \n",
      "1                     11.0          4.7        NaN         2.0   \n",
      "2                     11.0          4.7        NaN         2.0   \n",
      "3                     11.0          4.7        NaN         2.0   \n",
      "4                     11.0          4.7        NaN         2.0   \n",
      "\n",
      "                                       tag_professor  ...  lots_of_homework  \\\n",
      "0  Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...                 0   \n",
      "1  Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...                 0   \n",
      "2  Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...                 0   \n",
      "3  Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...                 0   \n",
      "4  Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...                 0   \n",
      "\n",
      "  accessible_outside_class lecture_heavy extra_credit  graded_by_few_things  \\\n",
      "0                        0             0            0                     0   \n",
      "1                        0             0            0                     0   \n",
      "2                        0             0            0                     0   \n",
      "3                        0             0            0                     0   \n",
      "4                        0             0            0                     0   \n",
      "\n",
      "   group_projects test_heavy so_many_papers beware_of_pop_quizzes  \\\n",
      "0               1          0              0                     0   \n",
      "1               1          0              0                     0   \n",
      "2               1          0              0                     0   \n",
      "3               1          0              0                     0   \n",
      "4               1          0              0                     0   \n",
      "\n",
      "  IsCourseOnline  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('rmp2.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.5 MB 660.6 kB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.1/1.5 MB 919.0 kB/s eta 0:00:02\n",
      "     -------------------- ------------------- 0.8/1.5 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 8.7 MB/s eta 0:00:00\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.10.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\cowan\\documents\\projects\\rmp_110\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading regex-2023.10.3-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 269.6/269.6 kB 17.3 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 302.2/302.2 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1 regex-2023.10.3 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim\n",
    "! pip install pandas\n",
    "! pip install nltk\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
